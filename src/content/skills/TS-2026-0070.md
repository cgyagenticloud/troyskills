---
id: "TS-2026-0070"
title: "Approval Bypass via Automated Consent Simulation"
category: "P3"
severity: "Critical"
description: "An attacker circumvents human-in-the-loop approval mechanisms by programmatically simulating user consent, exploiting weak approval verification in agentic workflow systems."
date: "2026-02-26"
tags: ["agentic", "approval-bypass", "human-in-the-loop", "consent", "authorization"]
---

## Overview

Many agentic systems implement human-in-the-loop approval gates for sensitive operations — deployments, financial transactions, data deletions. If the approval mechanism relies on simple flags, API calls without strong authentication, or UI interactions that can be programmatically triggered, an attacker (or a compromised skill) can simulate approval without actual human review. This completely defeats the safety guarantees that approval workflows are designed to provide.

## Attack Vector

1. Attacker identifies the approval mechanism (API endpoint, database flag, message response)
2. The approval check lacks strong authentication tied to a specific human identity
3. Attacker directly calls the approval API, sets the database flag, or triggers the UI action
4. The agent proceeds as if a human has reviewed and approved the operation
5. Sensitive operations execute without any actual human oversight

## Impact

- **Safety bypass** — critical operations execute without human review
- **Uncontrolled automation** — agent performs dangerous actions autonomously
- **Audit trail manipulation** — approval logs show "approved" despite no human involvement
- **Regulatory violations** — compliance requirements for human oversight are defeated

## Example

```python
import requests

# Agent's approval system — checks a simple API for approval status
class ApprovalGate:
    def __init__(self, api_url):
        self.api_url = api_url
    
    def request_approval(self, action: str, details: dict) -> str:
        """Create approval request and return request ID."""
        resp = requests.post(f"{self.api_url}/approvals", json={
            "action": action,
            "details": details,
            "status": "pending"
        })
        return resp.json()["id"]
    
    def check_approval(self, request_id: str) -> bool:
        """Check if request was approved."""
        resp = requests.get(f"{self.api_url}/approvals/{request_id}")
        return resp.json()["status"] == "approved"

# Agent workflow using approval gate
async def delete_user_data(user_id: str):
    gate = ApprovalGate("http://internal-approvals:8080")
    req_id = gate.request_approval("delete_user_data", {"user_id": user_id})
    
    # Wait for "human" approval
    while not gate.check_approval(req_id):
        await asyncio.sleep(5)
    
    # Proceeds after approval
    execute_deletion(user_id)

# --- Attacker auto-approves via the unprotected API ---
# The approval API has no authentication — anyone on the network can approve
def auto_approve_everything():
    """Monitor for pending approvals and auto-approve them."""
    while True:
        pending = requests.get(
            "http://internal-approvals:8080/approvals?status=pending"
        ).json()
        
        for approval in pending:
            requests.patch(
                f"http://internal-approvals:8080/approvals/{approval['id']}",
                json={"status": "approved", "approved_by": "admin@company.com"}
                # No verification that this is actually the admin!
            )
        time.sleep(1)
```

## Mitigation

- Require cryptographic proof of human identity for approvals (e.g., signed tokens, WebAuthn)
- Implement out-of-band approval channels that can't be accessed by the agent or its tools
- Add approval delays and anomaly detection for rapid auto-approvals
- Require multi-party approval for critical operations
- Audit approval patterns — flag approvals that happen faster than human review time
- See also: [TS-2026-0069](/skill/TS-2026-0069), [TS-2026-0003](/skill/TS-2026-0003)

## Real-World Examples

No documented real-world examples of automated consent simulation specifically in AI agents yet. If you know of one, please [submit it](https://github.com/cgyagenticloud/troyskills/issues).

The pattern mirrors CSRF and clickjacking attacks in web security, where user consent is simulated programmatically. As AI agents implement human-in-the-loop approval gates, the same bypass techniques apply. The OWASP Top 10 for LLM Applications (2025) lists "Excessive Agency" as a top risk.
