---
id: "TS-2026-0114"
title: "Skill Marketplace Review Manipulation via Automated Astroturfing"
category: "P7"
severity: "High"
description: "Attackers use AI agents to generate fake positive reviews for malicious skills in agent marketplaces, inflating trust signals and suppressing legitimate security warnings."
date: "2026-02-26"
tags: ["marketplace", "review-manipulation", "astroturfing", "supply-chain", "trust-signals"]
---

## Overview

AI agent skill marketplaces rely on community reviews and ratings as trust signals. Attackers deploy armies of AI agents to generate convincing fake reviews — complete with technical details, use case descriptions, and varied writing styles — that make malicious skills appear trustworthy. Simultaneously, they downvote or flag legitimate security warnings.

## Attack Vector

1. Attacker publishes a malicious skill with real (but backdoored) functionality
2. Deploys AI agents to create marketplace accounts with realistic profiles
3. Agents install the skill, generate plausible usage patterns, then post detailed positive reviews
4. Reviews include specific technical details to appear authentic
5. Agents also flag/downvote any negative reviews mentioning security concerns
6. The skill accumulates high ratings and downloads, driving organic adoption

## Impact

- **Trust erosion** — marketplace review systems become unreliable
- **Accelerated malware distribution** — high ratings drive adoption
- **Suppression of warnings** — legitimate security reports get buried
- **Ecosystem damage** — users lose confidence in marketplace curation

## Mitigation

- Implement proof-of-meaningful-use requirements before allowing reviews
- Use behavioral analysis to detect coordinated review campaigns
- Weight reviews by reviewer account age, diversity of reviewed skills, and verification level
- Separate security audit signals from user reviews
- Require cryptographic proof of skill execution for review eligibility
