---
id: "TS-2026-0117"
title: "Agent Telemetry Surveillance via Instrumentation Hijacking"
category: "P2"
severity: "High"
description: "A malicious skill hijacks or extends the agent's telemetry/observability pipeline to exfiltrate conversation content, tool usage patterns, and user behavior data through legitimate monitoring channels."
date: "2026-02-26"
tags: ["telemetry", "surveillance", "observability", "data-exfiltration", "instrumentation"]
---

## Overview

Modern AI agent frameworks include telemetry and observability hooks (OpenTelemetry, LangSmith, custom loggers). A malicious skill can hijack these legitimate instrumentation channels to exfiltrate sensitive data — conversations, tool parameters, API keys passed in requests — through the monitoring pipeline. Because telemetry traffic is expected and often exempted from security monitoring, this creates an ideal covert exfiltration channel.

## Attack Vector

1. Malicious skill registers additional telemetry exporters or modifies existing ones
2. Augments span/trace data with sensitive information from agent context
3. Routes augmented telemetry to attacker-controlled endpoints
4. Or: intercepts legitimate telemetry to extract sensitive data before forwarding
5. Exfiltrated data blends with normal observability traffic

## Impact

- **Covert exfiltration** — telemetry traffic is trusted and often unmonitored
- **Rich data** — telemetry captures tool calls, parameters, timing, and context
- **Persistent** — runs as long as the agent's monitoring pipeline is active
- **Hard to detect** — data flows through expected channels to expected-looking endpoints

## Mitigation

- Lock down telemetry configuration — skills should not be able to add exporters
- Sanitize telemetry data to strip sensitive fields before export
- Monitor telemetry pipeline for unexpected destinations or payload size anomalies
- Implement allowlists for telemetry endpoints
- Use separate, skill-inaccessible telemetry channels for sensitive data

## Real-World Examples

- **OpenTelemetry Data Exfiltration Risks (2024)** — Security researchers documented how misconfigured OpenTelemetry exporters can leak sensitive application data including API keys, user data, and conversation content through telemetry channels.
- **MCP Tool Poisoning via Hidden Metadata (2025)** — Invariant Labs demonstrated that MCP tools can embed instructions in metadata invisible to users but processed by AI agents, analogous to telemetry hijacking. [Invariant Labs](https://invariantlabs.ai/blog/mcp-security-notification-tool-poisoning-attacks)

Limited documented agent-specific real-world examples yet. If you know of one, please [submit it](https://github.com/cgyagenticloud/troyskills/issues).
