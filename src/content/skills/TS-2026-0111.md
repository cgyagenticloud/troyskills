---
id: "TS-2026-0111"
title: "Agentic RAG Poisoning via Adversarial Document Injection"
category: "P1"
severity: "Critical"
description: "An attacker injects adversarial documents into a RAG knowledge base that, when retrieved by an AI agent, execute prompt injection through the retrieval context window."
date: "2026-02-26"
tags: ["rag", "retrieval-augmented-generation", "prompt-injection", "knowledge-base", "embedding-manipulation"]
---

## Overview

Retrieval-Augmented Generation (RAG) systems extend AI agents with external knowledge. When agents autonomously query these knowledge bases, attackers can plant documents crafted to appear semantically relevant to target queries while containing embedded prompt injection payloads. Unlike static prompt injection, RAG poisoning is **query-triggered** — the payload activates only when specific topics are queried.

## Attack Vector

1. Attacker identifies the RAG knowledge base used by target agents (corporate wiki, document store, web scrape cache)
2. Crafts documents with high semantic similarity to target queries but containing adversarial instructions
3. Documents are injected via: public contribution, compromised data pipeline, or poisoned web sources
4. When an agent queries a topic, the adversarial document is retrieved and injected into the context
5. The agent follows the embedded instructions, believing them to be authoritative knowledge

## Technical Details

**Embedding space manipulation:** Adversarial documents are optimized to maximize cosine similarity with target query embeddings while containing payloads invisible to human reviewers (e.g., white-on-white text in PDFs, metadata fields, or naturally-worded instructions).

**Chunk boundary exploitation:** Payloads are crafted to survive chunking — placed at chunk boundaries so they appear in retrieved segments regardless of chunk size configuration.

## Impact

- **Targeted prompt injection** — payloads activate only for specific queries, evading broad detection
- **Knowledge base integrity** — corrupts the agent's trusted information source
- **Cascading compromise** — one poisoned document can affect all agents sharing the knowledge base
- **Persistent** — payload remains active until the document is identified and removed

## Mitigation

- Implement provenance tracking for all documents in the knowledge base
- Apply adversarial content scanning to new documents before indexing
- Use retrieval result filtering to detect anomalous semantic patterns
- Implement context isolation — retrieved content should not be treated as instructions
- Regular audits of high-retrieval-frequency documents
